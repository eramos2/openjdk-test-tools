{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import pprint\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from utils.preprocess_data import remove_time_stamp\n",
    "\n",
    "#from utils.queryDB import queryDBForTestOutput\n",
    "# from preprocessData import generateFeatureWordsList, generateLabelsIndex, \\\n",
    "#                             preprocessDBData, shuffleDataLabelPairs, \\\n",
    "#                             padding_processed_data, preprocessTFIDFData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data/GitHubData'\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "train_files = os.listdir(train_data_path)\n",
    "for train_file in train_files:\n",
    "    if (train_file.endswith('txt')):\n",
    "        train_label.append(train_file)\n",
    "        with open(os.path.join(train_data_path, train_file)) as f:\n",
    "            train_data.append(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp increase train data by multiplication\n",
    "increase_times = 8\n",
    "train_data *= increase_times\n",
    "train_label *= increase_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_git = pd.DataFrame([train_data, train_label]).T\n",
    "df_git.columns= ['git_issue_content', 'labels']\n",
    "df_git.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process git data\n",
    "df_git['git_issue_content'] = [remove_time_stamp(content) for content in df_git['git_issue_content']]\n",
    "df_git.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'data/JenkinsData'\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "test_files = os.listdir(test_data_path)\n",
    "for test_file in test_files:\n",
    "    if (test_file.endswith('txt')):\n",
    "        test_label.append(test_file)\n",
    "        with open(os.path.join(test_data_path, test_file)) as f:\n",
    "            test_data.append(f.read())\n",
    "\n",
    "df_jenkins = pd.DataFrame([test_data, test_label]).T\n",
    "df_jenkins.columns= ['jenkins_content', 'labels']\n",
    "df_jenkins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pre-process jenkins data\n",
    "df_jenkins['jenkins_content'] = [remove_time_stamp(content) for content in df_jenkins['jenkins_content']]\n",
    "df_jenkins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add train test matching in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_git['clean_text'] = df_git['git_issue_content'].apply(process_text)\n",
    "# df_git.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_df_git = df_git.copy()\n",
    "\n",
    "def create_label_dict(labels, label_dict_name2num, label_dict_num2name):\n",
    "    index = 0\n",
    "    for label in labels:\n",
    "        if label not in label_dict_name2num:\n",
    "            label_dict_num2name[index] = label\n",
    "            label_dict_name2num[label] = index\n",
    "            index += 1\n",
    "\n",
    "labels_git_name = clean_df_git.pop(\"labels\") \n",
    "label_dict_name2num = dict()\n",
    "label_dict_num2name = dict()\n",
    "create_label_dict(labels_git_name, label_dict_name2num, label_dict_num2name)\n",
    "labels_git_num = [label_dict_name2num[x] for x in labels_git_name]\n",
    "\n",
    "print(\"label_dict_name2num is \\n\",label_dict_name2num, '\\n')\n",
    "print(\"label_dict_num2name is \\n\",label_dict_num2name, '\\n')\n",
    "print(\"labels_git_num is \\n\", labels_git_num, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_git.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tfidf can add more parameter settings\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer_train_vectors = tfidf_vectorizer.fit_transform(clean_df_git.pop('git_issue_content'))\n",
    "\n",
    "train_df = pd.DataFrame.sparse.from_spmatrix(tfidf_vectorizer_train_vectors, columns=tfidf_vectorizer.get_feature_names())\n",
    "print(\"train data after tfidf: \\n\", train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add val when more data available\n",
    "val_df = train_df\n",
    "\n",
    "# test df is from jenkins\n",
    "clean_df_jenkins = df_jenkins.copy()\n",
    "labels_jenkins_name = clean_df_jenkins.pop(\"labels\")\n",
    "labels_jenkins_num = [label_dict_name2num[x] for x in labels_jenkins_name]\n",
    "print(\"test labels list: \", labels_jenkins_num)\n",
    "test_df = pd.DataFrame.sparse.from_spmatrix(tfidf_vectorizer.transform(clean_df_jenkins.pop('jenkins_content')), columns=tfidf_vectorizer.get_feature_names())\n",
    "print(\"test data after tfidf: \\n\", test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(labels_git_num)\n",
    "# add val when more data available# add val when more data available\n",
    "val_labels = np.array(labels_git_num)\n",
    "test_labels = np.array(labels_jenkins_num)\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1.\n",
    "standardScaler = StandardScaler()\n",
    "train_features = standardScaler.fit_transform(train_features)\n",
    "val_features = standardScaler.transform(val_features)\n",
    "test_features = standardScaler.transform(test_features)\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary models evaluation with default parameters\n",
    "\n",
    "#Creating a dict of the several models\n",
    "model_dict = {'Dummy Model' : DummyClassifier(random_state=3),\n",
    "              'Stochastic Gradient Descent Model' : SGDClassifier(random_state=3, loss='log'),\n",
    "              'Random Forest Model': RandomForestClassifier(random_state=3),\n",
    "              'Decsision Tree Model': DecisionTreeClassifier(random_state=3),\n",
    "              'AdaBoost Model': AdaBoostClassifier(random_state=3),\n",
    "              'Gaussian Naive Bayes Model': GaussianNB(),\n",
    "              'K Nearest Neighbor Model': KNeighborsClassifier()}\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "# X_train, X_test, y_train, y_test = train_features, val_features, train_labels, val_labels\n",
    "X_train, X_test, y_train, y_test = train_features, test_features, train_labels, test_labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "#                                                     y, \n",
    "#                                                     test_size = .3, \n",
    "#                                                     shuffle = True, \n",
    "#                                                     stratify = y, \n",
    "#                                                     random_state = 3)\n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_scores_df(model_dict):   \n",
    "    model_names, ac_scores_list, p_scores_list, r_scores_list, f1_scores_list = [], [], [], [], []\n",
    "    for cur_model_name,cur_model in model_dict.items():   \n",
    "        model_names.append(cur_model_name)\n",
    "        cur_model.fit(X_train, y_train)\n",
    "        label_pred = cur_model.predict(X_test)\n",
    "        ac_scores_list.append(accuracy_score(y_test, label_pred))\n",
    "        p_scores_list.append(precision_score(y_test, label_pred, average='macro'))\n",
    "        r_scores_list.append(recall_score(y_test, label_pred, average='macro'))\n",
    "        f1_scores_list.append(f1_score(y_test, label_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_names, ac_scores_list, p_scores_list, r_scores_list, f1_scores_list]).T\n",
    "        model_comparison_df.columns = ['model_names', 'accuracy_scores', 'precision_scores', 'recall_scores', 'f1_scores']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_scores', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "model_scores_df(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model in joblib format\n",
    "dump(model_dict[\"Random Forest Model\"], 'MLModel.joblib')\n"
   ]
  },
  {
   "source": [
    "# load and predict with saved model \n",
    "savedModel = load('MLModel.joblib')\n",
    "savedModel_predictions = savedModel.predict(test_features)\n",
    "print(\"savedModel Sample 0 predict label: \", savedModel_predictions[0])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model_dict[\"Random Forest Model\"].predict(test_features)\n",
    "predictions_proba = model_dict[\"Random Forest Model\"].predict_proba(test_features)\n",
    "\n",
    "# TF and sklearn have different functions for probability/confidence, below is sklearn\n",
    "print(\"Sample 0 predict with probability: \", predictions_proba[0])\n",
    "print(\"Sample 0 predict label: \", predictions[0])\n",
    "\n",
    "print(\"Sample 1 predict with probability: \", predictions_proba[2])\n",
    "print(\"Sample 1 predict label: \", predictions[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}